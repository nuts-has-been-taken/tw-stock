{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 市場新聞對行情影響\n",
    "這篇主要研究新聞與市場價格之間的關係\n",
    "\n",
    "## 假設\n",
    "可以做出以下假設來進行驗證\n",
    "- 新聞的看漲看跌會影響一部分的散戶操作\n",
    "- 市場價格會直接影響新聞報導\n",
    "\n",
    "## 目標\n",
    "期望目標有以下 : \n",
    "- 觀察股市新聞與價格之間的關係\n",
    "- 將新聞量化當成指標來進行操作\n",
    "\n",
    "## 計畫\n",
    "此篇研究可以分類成以下幾點 :\n",
    "1. 新聞數據蒐集\n",
    "2. 模型分析量化\n",
    "3. 數據研究證明\n",
    "\n",
    "### 新聞數據蒐集\n",
    "- 重點 :\n",
    "\n",
    "    從各種網站上蒐集新聞資料，範圍尺度該怎麼界定是需要很大的工程，股票市場是由各種各樣的類股組成，每組的權重也不一樣，不能全部都當成參考依據\n",
    "\n",
    "    因此最好的做法就是將範圍縮小到一支股票的新聞資訊。\n",
    "\n",
    "- 數據來源 :\n",
    "\n",
    "    目前有個股新聞且最好抓資料的是 [Goodinfo!](https://goodinfo.tw/tw/index.asp)，因此會以這個網站為基準，這個網站抓的資訊來源是以下幾站\n",
    "    - 公告訊息\n",
    "    - EToday新聞雲\n",
    "    - Anue鉅亨\n",
    "    - PR Newswire\n",
    "    - Investing.com\n",
    "\n",
    "### 模型分析量化\n",
    "- 重點 :\n",
    "\n",
    "    利用 AI model 來分析新聞是看漲看跌中立哪一個 label，模型主要有以下兩種\n",
    "    - 情感分析模型 (sentiment model) : 可以看成理解語意的分類器，只會回傳 label, score，任務單一，比較小型\n",
    "    - 大型語言模型 (LLM) : 能力取決於模型參數，要使用 API 付費會比較穩定，優點是可解釋性強\n",
    "\n",
    "- 本篇使用到的模型 :\n",
    "\n",
    "    下面兩個都是簡體中文訓練的 bert-base 公開 model，目前缺少公開的中文數據集因此很難自己訓練\n",
    "    - [yiyanghkust/finbert-tone-chinese](https://huggingface.co/yiyanghkust/finbert-tone-chinese/tree/main)\n",
    "    - [hw2942/bert-base-chinese-finetuning-financial-news-sentiment-v2](https://huggingface.co/hw2942/bert-base-chinese-finetuning-financial-news-sentiment-v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 數據蒐集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "\n",
    "def news_supplier_handler(supplier:str, url:str):\n",
    "    \"\"\"處理新聞文章\"\"\"\n",
    "    \n",
    "    content = \"\"\n",
    "    \n",
    "    if supplier==\"Anue鉅亨\":\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "        raw_content = soup.find(\"main\", id=\"article-container\").find_all(\"p\")\n",
    "    elif supplier==\"Investing.com\":\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        service = Service('./chromedriver')\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        raw_content = soup.find(\"div\", class_=\"article_WYSIWYG__O0uhw article_articlePage__UMz3q text-[18px] leading-8\").find_all(\"p\")\n",
    "    elif supplier==\"ETtoday新聞雲\":\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "        raw_content = soup.find(\"div\", class_=\"story\").find_all(\"p\")\n",
    "    elif supplier==\"PR Newswire\":\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        service = Service('./chromedriver')\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        driver.get(f'https://goodinfo.tw/tw/{url}')\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        raw_content = soup.find(\"div\", class_=\"b1 r10\").find_all(\"p\")\n",
    "    else: # 公告訊息\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        service = Service('./chromedriver')\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        driver.get(f'https://goodinfo.tw/tw/{url}')\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        raw_content = soup.find(\"td\", style=\"padding:16px 9px 16px 18px;font-size:11pt;line-height:28px;\")\n",
    "    for i in raw_content:\n",
    "            content += i.text\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "service = Service('./chromedriver')\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['date'] = None\n",
    "df['supplier'] = None\n",
    "df['link'] = None\n",
    "df['content'] = None\n",
    "\n",
    "error_index = []\n",
    "\n",
    "i = 4\n",
    "url = f\"\"\"https://goodinfo.tw/tw/StockAnnounceList.asp?PAGE=1&START_DT=202{i}-01-01&END_DT=202{i}-12-31&STOCK_ID=2330&KEY_WORD=&NEWS_SRC=公告訊息&NEWS_SRC=ETtoday新聞雲&NEWS_SRC=Anue鉅亨&NEWS_SRC=PR+Newswire&NEWS_SRC=Investing.com\"\"\"\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "page_count = soup.find(\"p\", style=\"font-size:11pt;margin-top:4pt;margin-bottom:0pt\").text.split(\"共\")[1][1:-3]\n",
    "for page in range(int(page_count)):\n",
    "    url = f\"\"\"https://goodinfo.tw/tw/StockAnnounceList.asp?PAGE={page+1}&START_DT=202{i}-01-01&END_DT=202{i}-12-31&STOCK_ID=2330&KEY_WORD=&NEWS_SRC=公告訊息&NEWS_SRC=ETtoday新聞雲&NEWS_SRC=Anue鉅亨&NEWS_SRC=PR+Newswire&NEWS_SRC=Investing.com\"\"\"\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    news_list = soup.find(\"div\",id=\"divNewsList\").find_all(\"tr\", valign=\"top\")\n",
    "    for news in news_list:\n",
    "        news_date = news.find(\"span\", style=\"font-size:9pt;color:gray;font-weight:normal;\").text\n",
    "        news_date = datetime.strptime(news_date[-17:-7], \"%Y/%m/%d\")\n",
    "        news = news.find_all(\"a\")\n",
    "        link = news[1].get('href')\n",
    "        news_supplier = news[0].text\n",
    "        try :\n",
    "            news_content = news_supplier_handler(news_supplier, link)\n",
    "            new_row = {'date':news_date, 'supplier':news_supplier, 'link':link, 'content':news_content}\n",
    "            df.loc[len(df)+1] = new_row\n",
    "        except:\n",
    "            new_row = {'date':news_date, 'supplier':news_supplier, 'link':link, 'content':None}\n",
    "            df.loc[len(df)+1] = new_row\n",
    "            error_index.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ddd = [3, 4, 6, 12, 13, 201, 341, 1338, 1403, 2088, 2161, 2444]\n",
    "error_index = [3, 4, 6, 12, 13, 341, 1403, 2161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.cnyes.com/news/id/5661594?utm_source=RWtaTXdQNjF2MkRWZDBscg==&utm_medium=NewsApi\n",
      "https://news.cnyes.com/news/id/5661539?utm_source=RWtaTXdQNjF2MkRWZDBscg==&utm_medium=NewsApi\n",
      "https://news.cnyes.com/news/id/5661087?utm_source=RWtaTXdQNjF2MkRWZDBscg==&utm_medium=NewsApi\n",
      "https://news.cnyes.com/news/id/5660941?utm_source=RWtaTXdQNjF2MkRWZDBscg==&utm_medium=NewsApi\n",
      "https://news.cnyes.com/news/id/5660946?utm_source=RWtaTXdQNjF2MkRWZDBscg==&utm_medium=NewsApi\n",
      "https://hk.investing.com/news/stock-market-news/article-571572\n",
      "https://hk.investing.com/news/stock-market-news/article-506647\n",
      "https://hk.investing.com/news/economy/article-463349\n"
     ]
    }
   ],
   "source": [
    "for i in error_index:\n",
    "    print(df.loc[i, 'link'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_page_handle(df:pd.DataFrame, error_index:list):\n",
    "    error_trying = 0\n",
    "    while error_index:\n",
    "        try:\n",
    "            index = error_index[0]\n",
    "            supplier = df['supplier'][index]\n",
    "            link = df['link'][index]\n",
    "            content = news_supplier_handler(supplier=supplier, url=link)\n",
    "            df.at[index, 'content'] = content\n",
    "            print(f\"index:{index}   擷取成功\")\n",
    "            error_index.pop(0)\n",
    "        except:\n",
    "            if error_trying>=10:\n",
    "                break\n",
    "            error_trying+=1\n",
    "            print(f\"index:{index} 擷取失敗 重新嘗試中...\")\n",
    "    return df, error_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "暫存流量限制，因為爬蟲過程漫長且網站有阻擋機制，因此分批處理後做整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df\n",
    "temp_error_index = error_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:3   擷取成功\n",
      "index:4   擷取成功\n",
      "index:6   擷取成功\n",
      "index:12   擷取成功\n",
      "index:13   擷取成功\n",
      "index:341   擷取成功\n",
      "index:1403   擷取成功\n",
      "index:2161   擷取成功\n"
     ]
    }
   ],
   "source": [
    "temp_df, error_index = error_page_handle(temp_df, temp_error_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_json(\"2024_news.json\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 模型分析量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "delimiters = \"[， 。]\"\n",
    "\n",
    "def split_text_by_length(text, max_length=512):\n",
    "    words = re.split(delimiters, text)\n",
    "    split_texts = []\n",
    "    current_part = []\n",
    "    current_length = 0\n",
    "\n",
    "    for word in words:\n",
    "        if current_length + len(word) + 1 <= max_length:\n",
    "            current_part.append(word)\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            split_texts.append(' '.join(current_part))\n",
    "            current_part = [word]\n",
    "            current_length = len(word) + 1\n",
    "\n",
    "    if current_part:\n",
    "        split_texts.append(' '.join(current_part))\n",
    "\n",
    "    return split_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "1.事實發生日:112/12/08\n",
    "2.公司名稱:台灣積體電路製造股份有限公司\n",
    "3.與公司關係(請輸入本公司或子公司):本公司\n",
    "4.相互持股比例:不適用\n",
    "5.發生緣由:不適用\n",
    "6.因應措施:不適用\n",
    "7.其他應敘明事項(若事件發生或決議之主體係屬公開發行以上公司，本則重大訊息同時\n",
    "  符合證券交易法施行細則第7條第9款所定對股東權益或證券價格有重大影響之事項):\n",
    "台積公司今（8）日公佈2023年11月營收報告。2023年11月合併營收約為新台幣\n",
    "2,060億2,600萬元，較上月減少了15.3%，較去年同期減少了7.5%。累計2023年1至\n",
    "11月營收約為新台幣1兆9,854億3,600萬元，較去年同期減少了4.1%。\"\"\"\n",
    "\n",
    "text = split_text_by_length(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from typing import Literal\n",
    "import torch\n",
    "def sentiment_model_label(model:Literal['finbert-tone-chinese', 'bert-base-chinese-finetuning-financial-news-sentiment-v2']):\n",
    "    \"\"\"label news documents with sentiment model\n",
    "\n",
    "    Args:\n",
    "        model (str): choose two different model\n",
    "    \"\"\"\n",
    "    model_name = f\"../model/{model}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "    nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "    result = nlp(text[0])\n",
    "    \n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
