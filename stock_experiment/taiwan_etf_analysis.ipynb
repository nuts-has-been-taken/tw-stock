{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å°è‚¡ETFæˆä»½è‚¡èˆ‡æ¬Šé‡åˆ†æ\n",
    "\n",
    "æœ¬ç¯‡åˆ†æå°ç£è‚¡å¸‚æ‰€æœ‰ETFçš„æˆä»½è‚¡æ§‹æˆå’Œæ¬Šé‡åˆ†é…ï¼Œä¸¦æä¾›è‡ªå‹•åŒ–æ•¸æ“šæ”¶é›†åŠŸèƒ½ã€‚\n",
    "\n",
    "## åŠŸèƒ½ç‰¹è‰²\n",
    "1. è‡ªå‹•å–å¾—æ‰€æœ‰å°è‚¡ETFæ¸…å–®\n",
    "2. çˆ¬å–æ¯å€‹ETFçš„æˆä»½è‚¡å’Œæ¬Šé‡\n",
    "3. è³‡æ–™å„²å­˜èˆ‡è®€å–åŠŸèƒ½\n",
    "4. ETFæˆä»½è‚¡é‡ç–Šåº¦åˆ†æ\n",
    "5. æ¬Šé‡åˆ†å¸ƒè¦–è¦ºåŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŒ¯å…¥å¿…è¦å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ä¸­æ–‡å­—é«”è¨­å®š\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETFæ•¸æ“šæ”¶é›†é¡åˆ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaiwanETFAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.etf_list = []\n",
    "        self.etf_constituents = {}\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "        \n",
    "    def get_etf_list(self):\n",
    "        \"\"\"å–å¾—æ‰€æœ‰å°è‚¡ETFæ¸…å–®\"\"\"\n",
    "        try:\n",
    "            # TWSE ETFæ¸…å–®API\n",
    "            url = \"https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX?response=json&type=ALL\"\n",
    "            response = self.session.get(url)\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'data9' in data:  # ETFè³‡æ–™é€šå¸¸åœ¨data9\n",
    "                etf_data = data['data9']\n",
    "                self.etf_list = []\n",
    "                \n",
    "                for item in etf_data:\n",
    "                    if len(item) >= 2:\n",
    "                        etf_code = item[0]\n",
    "                        etf_name = item[1]\n",
    "                        \n",
    "                        # éæ¿¾ETF (é€šå¸¸ä»£ç¢¼æ ¼å¼ç‚º4ç¢¼æ•¸å­—)\n",
    "                        if len(etf_code) == 4 and etf_code.isdigit():\n",
    "                            self.etf_list.append({\n",
    "                                'code': etf_code,\n",
    "                                'name': etf_name,\n",
    "                                'full_code': f\"{etf_code}.TW\"\n",
    "                            })\n",
    "                            \n",
    "            # è£œå……å¸¸è¦‹ETFæ¸…å–®\n",
    "            common_etfs = [\n",
    "                {'code': '0050', 'name': 'å…ƒå¤§å°ç£50', 'full_code': '0050.TW'},\n",
    "                {'code': '0056', 'name': 'å…ƒå¤§é«˜è‚¡æ¯', 'full_code': '0056.TW'},\n",
    "                {'code': '00878', 'name': 'åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯', 'full_code': '00878.TW'},\n",
    "                {'code': '00881', 'name': 'åœ‹æ³°å°ç£5G+', 'full_code': '00881.TW'},\n",
    "                {'code': '00692', 'name': 'å¯Œé‚¦å…¬å¸æ²»ç†', 'full_code': '00692.TW'},\n",
    "                {'code': '00757', 'name': 'çµ±ä¸€FANG+', 'full_code': '00757.TW'},\n",
    "                {'code': '00762', 'name': 'å…ƒå¤§å…¨çƒäººå·¥æ™ºæ…§', 'full_code': '00762.TW'},\n",
    "                {'code': '00894', 'name': 'ä¸­ä¿¡å°è³‡é«˜è‚¡æ¯', 'full_code': '00894.TW'},\n",
    "                {'code': '00919', 'name': 'ç¾¤ç›Šå°ç£ç²¾é¸é«˜æ¯', 'full_code': '00919.TW'},\n",
    "                {'code': '00929', 'name': 'å¾©è¯å°ç£ç§‘æŠ€å„ªæ¯', 'full_code': '00929.TW'}\n",
    "            ]\n",
    "            \n",
    "            # åˆä½µä¸¦å»é‡\n",
    "            existing_codes = {etf['code'] for etf in self.etf_list}\n",
    "            for etf in common_etfs:\n",
    "                if etf['code'] not in existing_codes:\n",
    "                    self.etf_list.append(etf)\n",
    "            \n",
    "            print(f\"æ‰¾åˆ° {len(self.etf_list)} æª”ETF\")\n",
    "            return self.etf_list\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"å–å¾—ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def get_etf_constituents(self, etf_code):\n",
    "        \"\"\"å–å¾—ç‰¹å®šETFçš„æˆä»½è‚¡å’Œæ¬Šé‡\"\"\"\n",
    "        try:\n",
    "            # æ–¹æ³•1: æŠ•ä¿¡æŠ•é¡§å…¬æœƒAPI\n",
    "            url = f\"https://www.sitca.org.tw/ROC/Industry/IN2421.aspx?txtMonth={datetime.now().strftime('%Y%m')}&txtStkNo={etf_code}\"\n",
    "            response = self.session.get(url)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                # è§£ææˆä»½è‚¡è¡¨æ ¼\n",
    "                tables = soup.find_all('table')\n",
    "                \n",
    "                for table in tables:\n",
    "                    rows = table.find_all('tr')\n",
    "                    if len(rows) > 1:  # æœ‰è³‡æ–™çš„è¡¨æ ¼\n",
    "                        constituents = []\n",
    "                        for row in rows[1:]:  # è·³éæ¨™é¡Œè¡Œ\n",
    "                            cols = row.find_all(['td', 'th'])\n",
    "                            if len(cols) >= 3:\n",
    "                                stock_code = cols[0].get_text(strip=True)\n",
    "                                stock_name = cols[1].get_text(strip=True)\n",
    "                                weight_text = cols[2].get_text(strip=True)\n",
    "                                \n",
    "                                # è§£ææ¬Šé‡\n",
    "                                try:\n",
    "                                    weight = float(weight_text.replace('%', '').replace(',', ''))\n",
    "                                    constituents.append({\n",
    "                                        'stock_code': stock_code,\n",
    "                                        'stock_name': stock_name,\n",
    "                                        'weight': weight\n",
    "                                    })\n",
    "                                except:\n",
    "                                    continue\n",
    "                        \n",
    "                        if constituents:\n",
    "                            return constituents\n",
    "            \n",
    "            # æ–¹æ³•2: ä½¿ç”¨TWSE APIå˜—è©¦å–å¾—è³‡æ–™\n",
    "            date_str = datetime.now().strftime('%Y%m%d')\n",
    "            url2 = f\"https://www.twse.com.tw/rwd/zh/fund/T86?response=json&date={date_str}&selectType=ETF\"\n",
    "            response2 = self.session.get(url2)\n",
    "            \n",
    "            if response2.status_code == 200:\n",
    "                data = response2.json()\n",
    "                if 'data' in data:\n",
    "                    # è™•ç†TWSE ETFè³‡æ–™\n",
    "                    pass\n",
    "            \n",
    "            # æ–¹æ³•3: ä½¿ç”¨æ¨¡æ“¬è³‡æ–™ (å¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦æ›¿æ›ç‚ºçœŸå¯¦API)\n",
    "            return self._get_mock_constituents(etf_code)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"å–å¾— {etf_code} æˆä»½è‚¡æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def _get_mock_constituents(self, etf_code):\n",
    "        \"\"\"æ¨¡æ“¬æˆä»½è‚¡è³‡æ–™ (å¯¦éš›ä½¿ç”¨æ™‚éœ€æ›¿æ›ç‚ºçœŸå¯¦API)\"\"\"\n",
    "        mock_data = {\n",
    "            '0050': [\n",
    "                {'stock_code': '2330', 'stock_name': 'å°ç©é›»', 'weight': 47.5},\n",
    "                {'stock_code': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'weight': 8.2},\n",
    "                {'stock_code': '2317', 'stock_name': 'é´»æµ·', 'weight': 4.1},\n",
    "                {'stock_code': '2308', 'stock_name': 'å°é”é›»', 'weight': 2.8},\n",
    "                {'stock_code': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'weight': 2.5}\n",
    "            ],\n",
    "            '0056': [\n",
    "                {'stock_code': '2330', 'stock_name': 'å°ç©é›»', 'weight': 15.2},\n",
    "                {'stock_code': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'weight': 8.9},\n",
    "                {'stock_code': '2317', 'stock_name': 'é´»æµ·', 'weight': 6.7},\n",
    "                {'stock_code': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'weight': 4.3},\n",
    "                {'stock_code': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'weight': 3.8}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return mock_data.get(etf_code, [])\n",
    "    \n",
    "    def collect_all_etf_data(self, max_etfs=10):\n",
    "        \"\"\"æ”¶é›†æ‰€æœ‰ETFçš„æˆä»½è‚¡è³‡æ–™\"\"\"\n",
    "        if not self.etf_list:\n",
    "            self.get_etf_list()\n",
    "        \n",
    "        print(f\"é–‹å§‹æ”¶é›† {min(len(self.etf_list), max_etfs)} æª”ETFçš„æˆä»½è‚¡è³‡æ–™...\")\n",
    "        \n",
    "        for i, etf in enumerate(self.etf_list[:max_etfs]):\n",
    "            print(f\"æ­£åœ¨è™•ç† {i+1}/{min(len(self.etf_list), max_etfs)}: {etf['code']} {etf['name']}\")\n",
    "            \n",
    "            constituents = self.get_etf_constituents(etf['code'])\n",
    "            if constituents:\n",
    "                self.etf_constituents[etf['code']] = {\n",
    "                    'name': etf['name'],\n",
    "                    'constituents': constituents,\n",
    "                    'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                }\n",
    "                print(f\"  æ‰¾åˆ° {len(constituents)} æª”æˆä»½è‚¡\")\n",
    "            else:\n",
    "                print(f\"  ç„¡æ³•å–å¾—æˆä»½è‚¡è³‡æ–™\")\n",
    "            \n",
    "            # é¿å…éåº¦è«‹æ±‚\n",
    "            time.sleep(1)\n",
    "        \n",
    "        print(f\"\\nè³‡æ–™æ”¶é›†å®Œæˆï¼æˆåŠŸå–å¾— {len(self.etf_constituents)} æª”ETFçš„æˆä»½è‚¡è³‡æ–™\")\n",
    "        return self.etf_constituents\n",
    "    \n",
    "    def save_data_to_csv(self, directory=\"../data/etf_data/\"):\n",
    "        \"\"\"å°‡ETFè³‡æ–™å„²å­˜ç‚ºCSVæª”æ¡ˆ\"\"\"\n",
    "        import os\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        \n",
    "        # å„²å­˜ETFæ¸…å–®\n",
    "        etf_df = pd.DataFrame(self.etf_list)\n",
    "        etf_df.to_csv(f\"{directory}etf_list.csv\", index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # å„²å­˜å„ETFæˆä»½è‚¡è³‡æ–™\n",
    "        for etf_code, data in self.etf_constituents.items():\n",
    "            constituents_df = pd.DataFrame(data['constituents'])\n",
    "            constituents_df['etf_code'] = etf_code\n",
    "            constituents_df['etf_name'] = data['name']\n",
    "            constituents_df['last_update'] = data['last_update']\n",
    "            constituents_df.to_csv(f\"{directory}{etf_code}_constituents.csv\", index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # å„²å­˜åˆä½µè³‡æ–™\n",
    "        all_data = []\n",
    "        for etf_code, data in self.etf_constituents.items():\n",
    "            for constituent in data['constituents']:\n",
    "                all_data.append({\n",
    "                    'etf_code': etf_code,\n",
    "                    'etf_name': data['name'],\n",
    "                    'stock_code': constituent['stock_code'],\n",
    "                    'stock_name': constituent['stock_name'],\n",
    "                    'weight': constituent['weight'],\n",
    "                    'last_update': data['last_update']\n",
    "                })\n",
    "        \n",
    "        all_df = pd.DataFrame(all_data)\n",
    "        all_df.to_csv(f\"{directory}all_etf_constituents.csv\", index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"è³‡æ–™å·²å„²å­˜è‡³ {directory}\")\n",
    "        return all_df\n",
    "    \n",
    "    def load_data_from_csv(self, directory=\"../data/etf_data/\"):\n",
    "        \"\"\"å¾CSVæª”æ¡ˆè¼‰å…¥ETFè³‡æ–™\"\"\"\n",
    "        try:\n",
    "            # è¼‰å…¥ETFæ¸…å–®\n",
    "            etf_df = pd.read_csv(f\"{directory}etf_list.csv\")\n",
    "            self.etf_list = etf_df.to_dict('records')\n",
    "            \n",
    "            # è¼‰å…¥æˆä»½è‚¡è³‡æ–™\n",
    "            all_df = pd.read_csv(f\"{directory}all_etf_constituents.csv\")\n",
    "            \n",
    "            # é‡å»ºetf_constituentsçµæ§‹\n",
    "            self.etf_constituents = {}\n",
    "            for etf_code in all_df['etf_code'].unique():\n",
    "                etf_data = all_df[all_df['etf_code'] == etf_code]\n",
    "                constituents = []\n",
    "                \n",
    "                for _, row in etf_data.iterrows():\n",
    "                    constituents.append({\n",
    "                        'stock_code': row['stock_code'],\n",
    "                        'stock_name': row['stock_name'],\n",
    "                        'weight': row['weight']\n",
    "                    })\n",
    "                \n",
    "                self.etf_constituents[etf_code] = {\n",
    "                    'name': etf_data.iloc[0]['etf_name'],\n",
    "                    'constituents': constituents,\n",
    "                    'last_update': etf_data.iloc[0]['last_update']\n",
    "                }\n",
    "            \n",
    "            print(f\"å·²è¼‰å…¥ {len(self.etf_list)} æª”ETFæ¸…å–®\")\n",
    "            print(f\"å·²è¼‰å…¥ {len(self.etf_constituents)} æª”ETFæˆä»½è‚¡è³‡æ–™\")\n",
    "            return all_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"è¼‰å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETFåˆ†æåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETFAnalyzer:\n",
    "    def __init__(self, etf_data):\n",
    "        self.etf_data = etf_data\n",
    "        self.all_df = None\n",
    "        \n",
    "    def create_analysis_dataframe(self):\n",
    "        \"\"\"å»ºç«‹åˆ†æç”¨çš„DataFrame\"\"\"\n",
    "        all_data = []\n",
    "        for etf_code, data in self.etf_data.items():\n",
    "            for constituent in data['constituents']:\n",
    "                all_data.append({\n",
    "                    'etf_code': etf_code,\n",
    "                    'etf_name': data['name'],\n",
    "                    'stock_code': constituent['stock_code'],\n",
    "                    'stock_name': constituent['stock_name'],\n",
    "                    'weight': constituent['weight']\n",
    "                })\n",
    "        \n",
    "        self.all_df = pd.DataFrame(all_data)\n",
    "        return self.all_df\n",
    "    \n",
    "    def get_stock_etf_exposure(self, stock_code=None):\n",
    "        \"\"\"åˆ†æå€‹è‚¡åœ¨å„ETFä¸­çš„æ¬Šé‡åˆ†å¸ƒ\"\"\"\n",
    "        if self.all_df is None:\n",
    "            self.create_analysis_dataframe()\n",
    "        \n",
    "        if stock_code:\n",
    "            stock_data = self.all_df[self.all_df['stock_code'] == stock_code]\n",
    "            return stock_data.sort_values('weight', ascending=False)\n",
    "        else:\n",
    "            # å›å‚³æ‰€æœ‰å€‹è‚¡çš„ETFæ›éšªåº¦\n",
    "            exposure = self.all_df.groupby('stock_code').agg({\n",
    "                'stock_name': 'first',\n",
    "                'weight': ['sum', 'mean', 'count'],\n",
    "                'etf_code': 'count'\n",
    "            }).round(2)\n",
    "            \n",
    "            exposure.columns = ['stock_name', 'total_weight', 'avg_weight', 'weight_count', 'etf_count']\n",
    "            return exposure.sort_values('total_weight', ascending=False)\n",
    "    \n",
    "    def get_etf_overlap(self, etf1, etf2):\n",
    "        \"\"\"åˆ†æå…©å€‹ETFçš„é‡ç–Šåº¦\"\"\"\n",
    "        if self.all_df is None:\n",
    "            self.create_analysis_dataframe()\n",
    "        \n",
    "        etf1_stocks = set(self.all_df[self.all_df['etf_code'] == etf1]['stock_code'])\n",
    "        etf2_stocks = set(self.all_df[self.all_df['etf_code'] == etf2]['stock_code'])\n",
    "        \n",
    "        overlap_stocks = etf1_stocks & etf2_stocks\n",
    "        overlap_ratio = len(overlap_stocks) / len(etf1_stocks | etf2_stocks)\n",
    "        \n",
    "        # å–å¾—é‡ç–Šè‚¡ç¥¨çš„æ¬Šé‡è³‡è¨Š\n",
    "        overlap_data = []\n",
    "        for stock in overlap_stocks:\n",
    "            etf1_weight = self.all_df[(self.all_df['etf_code'] == etf1) & (self.all_df['stock_code'] == stock)]['weight'].iloc[0]\n",
    "            etf2_weight = self.all_df[(self.all_df['etf_code'] == etf2) & (self.all_df['stock_code'] == stock)]['weight'].iloc[0]\n",
    "            stock_name = self.all_df[self.all_df['stock_code'] == stock]['stock_name'].iloc[0]\n",
    "            \n",
    "            overlap_data.append({\n",
    "                'stock_code': stock,\n",
    "                'stock_name': stock_name,\n",
    "                f'{etf1}_weight': etf1_weight,\n",
    "                f'{etf2}_weight': etf2_weight,\n",
    "                'weight_diff': abs(etf1_weight - etf2_weight)\n",
    "            })\n",
    "        \n",
    "        overlap_df = pd.DataFrame(overlap_data)\n",
    "        \n",
    "        return {\n",
    "            'overlap_ratio': overlap_ratio,\n",
    "            'overlap_count': len(overlap_stocks),\n",
    "            'total_unique_stocks': len(etf1_stocks | etf2_stocks),\n",
    "            'overlap_details': overlap_df.sort_values('weight_diff', ascending=False)\n",
    "        }\n",
    "    \n",
    "    def plot_etf_composition(self, etf_code, top_n=10):\n",
    "        \"\"\"ç¹ªè£½ETFæˆä»½è‚¡æ¬Šé‡åœ–\"\"\"\n",
    "        if etf_code not in self.etf_data:\n",
    "            print(f\"æ‰¾ä¸åˆ°ETF {etf_code}çš„è³‡æ–™\")\n",
    "            return\n",
    "        \n",
    "        constituents = self.etf_data[etf_code]['constituents']\n",
    "        df = pd.DataFrame(constituents).sort_values('weight', ascending=False).head(top_n)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # åœ“é¤…åœ–\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.pie(df['weight'], labels=df['stock_name'], autopct='%1.1f%%', startangle=90)\n",
    "        plt.title(f'{self.etf_data[etf_code][\"name\"]} ({etf_code}) å‰{top_n}å¤§æˆä»½è‚¡æ¬Šé‡åˆ†å¸ƒ', fontsize=14)\n",
    "        \n",
    "        # é•·æ¢åœ–\n",
    "        plt.subplot(2, 1, 2)\n",
    "        bars = plt.bar(range(len(df)), df['weight'])\n",
    "        plt.xlabel('æˆä»½è‚¡')\n",
    "        plt.ylabel('æ¬Šé‡ (%)')\n",
    "        plt.title(f'{self.etf_data[etf_code][\"name\"]} ({etf_code}) å‰{top_n}å¤§æˆä»½è‚¡æ¬Šé‡', fontsize=14)\n",
    "        plt.xticks(range(len(df)), [f'{row[\"stock_code\"]}\\n{row[\"stock_name\"]}' for _, row in df.iterrows()], \n",
    "                   rotation=45, ha='right')\n",
    "        \n",
    "        # åœ¨é•·æ¢åœ–ä¸Šæ¨™ç¤ºæ•¸å€¼\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1, f'{height:.1f}%',\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_stock_etf_exposure(self, stock_code):\n",
    "        \"\"\"ç¹ªè£½å€‹è‚¡åœ¨å„ETFä¸­çš„æ¬Šé‡åˆ†å¸ƒ\"\"\"\n",
    "        exposure_data = self.get_stock_etf_exposure(stock_code)\n",
    "        \n",
    "        if exposure_data.empty:\n",
    "            print(f\"æ‰¾ä¸åˆ°è‚¡ç¥¨ {stock_code} çš„ETFæ›éšªè³‡æ–™\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        bars = plt.bar(range(len(exposure_data)), exposure_data['weight'])\n",
    "        plt.xlabel('ETF')\n",
    "        plt.ylabel('æ¬Šé‡ (%)')\n",
    "        plt.title(f'{exposure_data.iloc[0][\"stock_name\"]} ({stock_code}) åœ¨å„ETFä¸­çš„æ¬Šé‡åˆ†å¸ƒ', fontsize=14)\n",
    "        plt.xticks(range(len(exposure_data)), \n",
    "                   [f'{row[\"etf_code\"]}\\n{row[\"etf_name\"][:10]}...' for _, row in exposure_data.iterrows()], \n",
    "                   rotation=45, ha='right')\n",
    "        \n",
    "        # åœ¨é•·æ¢åœ–ä¸Šæ¨™ç¤ºæ•¸å€¼\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1, f'{height:.1f}%',\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_summary_report(self):\n",
    "        \"\"\"ç”ŸæˆETFåˆ†ææ‘˜è¦å ±å‘Š\"\"\"\n",
    "        if self.all_df is None:\n",
    "            self.create_analysis_dataframe()\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(\"å°è‚¡ETFæˆä»½è‚¡åˆ†ææ‘˜è¦å ±å‘Š\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:\")\n",
    "        print(f\"  - åˆ†æETFæ•¸é‡: {len(self.etf_data)}\")\n",
    "        print(f\"  - ç¸½æˆä»½è‚¡æ•¸é‡: {len(self.all_df)}\")\n",
    "        print(f\"  - ç¨ç‰¹è‚¡ç¥¨æ•¸é‡: {self.all_df['stock_code'].nunique()}\")\n",
    "        \n",
    "        print(f\"\\nğŸ† æœ€å¸¸å‡ºç¾çš„æˆä»½è‚¡ (å‰10å):\")\n",
    "        top_stocks = self.all_df['stock_code'].value_counts().head(10)\n",
    "        for i, (stock_code, count) in enumerate(top_stocks.items(), 1):\n",
    "            stock_name = self.all_df[self.all_df['stock_code'] == stock_code]['stock_name'].iloc[0]\n",
    "            print(f\"  {i:2d}. {stock_code} {stock_name}: å‡ºç¾åœ¨ {count} æª”ETFä¸­\")\n",
    "        \n",
    "        print(f\"\\nğŸ’° ç¸½æ¬Šé‡æœ€é«˜çš„å€‹è‚¡ (å‰10å):\")\n",
    "        weight_summary = self.get_stock_etf_exposure().head(10)\n",
    "        for i, (stock_code, row) in enumerate(weight_summary.iterrows(), 1):\n",
    "            print(f\"  {i:2d}. {stock_code} {row['stock_name']}: ç¸½æ¬Šé‡ {row['total_weight']:.1f}% (å¹³å‡ {row['avg_weight']:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ ETFè¦æ¨¡åˆ†æ:\")\n",
    "        etf_sizes = self.all_df.groupby('etf_code')['stock_code'].count().sort_values(ascending=False)\n",
    "        for etf_code, size in etf_sizes.items():\n",
    "            etf_name = self.etf_data[etf_code]['name']\n",
    "            print(f\"  - {etf_code} {etf_name}: {size} æª”æˆä»½è‚¡\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. åˆå§‹åŒ–ETFåˆ†æå™¨ä¸¦æ”¶é›†è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ETFåˆ†æå™¨\n",
    "analyzer = TaiwanETFAnalyzer()\n",
    "\n",
    "# å–å¾—ETFæ¸…å–®\n",
    "etf_list = analyzer.get_etf_list()\n",
    "print(f\"æ‰¾åˆ° {len(etf_list)} æª”ETF\")\n",
    "\n",
    "# é¡¯ç¤ºå‰10æª”ETF\n",
    "for i, etf in enumerate(etf_list[:10]):\n",
    "    print(f\"{i+1:2d}. {etf['code']} - {etf['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. æ”¶é›†ETFæˆä»½è‚¡è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ”¶é›†å‰5æª”ETFçš„æˆä»½è‚¡è³‡æ–™ (å¯¦éš›ä½¿ç”¨æ™‚å¯ä»¥èª¿æ•´æ•¸é‡)\n",
    "etf_data = analyzer.collect_all_etf_data(max_etfs=5)\n",
    "\n",
    "# é¡¯ç¤ºæ”¶é›†åˆ°çš„è³‡æ–™\n",
    "for etf_code, data in etf_data.items():\n",
    "    print(f\"\\n{etf_code} - {data['name']}:\")\n",
    "    print(f\"æˆä»½è‚¡æ•¸é‡: {len(data['constituents'])}\")\n",
    "    print(\"å‰5å¤§æˆä»½è‚¡:\")\n",
    "    for i, constituent in enumerate(data['constituents'][:5]):\n",
    "        print(f\"  {i+1}. {constituent['stock_code']} {constituent['stock_name']}: {constituent['weight']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. å„²å­˜è³‡æ–™åˆ°CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„²å­˜è³‡æ–™\n",
    "all_data_df = analyzer.save_data_to_csv()\n",
    "\n",
    "# é¡¯ç¤ºå„²å­˜çš„è³‡æ–™æ¦‚è¦½\n",
    "print(\"\\nè³‡æ–™æ¦‚è¦½:\")\n",
    "print(all_data_df.head())\n",
    "print(f\"\\nç¸½ç­†æ•¸: {len(all_data_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ETFåˆ†æåŠŸèƒ½å±•ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹åˆ†æå™¨\n",
    "etf_analyzer = ETFAnalyzer(analyzer.etf_constituents)\n",
    "\n",
    "# ç”Ÿæˆæ‘˜è¦å ±å‘Š\n",
    "etf_analyzer.generate_summary_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. è¦–è¦ºåŒ–åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¹ªè£½ç‰¹å®šETFçš„æˆä»½è‚¡æ¬Šé‡åˆ†å¸ƒ\n",
    "if '0050' in analyzer.etf_constituents:\n",
    "    etf_analyzer.plot_etf_composition('0050', top_n=10)\n",
    "    \n",
    "# ç¹ªè£½å°ç©é›»åœ¨å„ETFä¸­çš„æ¬Šé‡åˆ†å¸ƒ\n",
    "etf_analyzer.plot_stock_etf_exposure('2330')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ETFé‡ç–Šåº¦åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æå…©å€‹ETFçš„é‡ç–Šåº¦\n",
    "if '0050' in analyzer.etf_constituents and '0056' in analyzer.etf_constituents:\n",
    "    overlap_result = etf_analyzer.get_etf_overlap('0050', '0056')\n",
    "    \n",
    "    print(f\"ETF 0050 èˆ‡ 0056 é‡ç–Šåˆ†æ:\")\n",
    "    print(f\"é‡ç–Šæ¯”ä¾‹: {overlap_result['overlap_ratio']:.2%}\")\n",
    "    print(f\"é‡ç–Šè‚¡ç¥¨æ•¸: {overlap_result['overlap_count']}\")\n",
    "    print(f\"ç¸½ç¨ç‰¹è‚¡ç¥¨æ•¸: {overlap_result['total_unique_stocks']}\")\n",
    "    \n",
    "    print(\"\\né‡ç–Šè‚¡ç¥¨è©³ç´°è³‡è¨Š:\")\n",
    "    print(overlap_result['overlap_details'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. å€‹è‚¡ETFæ›éšªåˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æå°ç©é›»çš„ETFæ›éšª\n",
    "tsmc_exposure = etf_analyzer.get_stock_etf_exposure('2330')\n",
    "print(\"å°ç©é›» (2330) çš„ETFæ›éšªåˆ†æ:\")\n",
    "print(tsmc_exposure)\n",
    "\n",
    "# å–å¾—æ‰€æœ‰å€‹è‚¡çš„ETFæ›éšªæ‘˜è¦\n",
    "all_exposure = etf_analyzer.get_stock_etf_exposure()\n",
    "print(\"\\næ‰€æœ‰å€‹è‚¡ETFæ›éšªæ‘˜è¦ (å‰10å):\")\n",
    "print(all_exposure.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é€²éšåˆ†æåŠŸèƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç”¢æ¥­åˆ†å¸ƒåˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€™è£¡å¯ä»¥çµåˆä¹‹å‰çš„å…¬å¸å¥åº·åˆ†æåŠŸèƒ½\n",
    "# åˆ†æETFçš„ç”¢æ¥­åˆ†å¸ƒå’Œå¥åº·åº¦è©•åˆ†\n",
    "\n",
    "def analyze_etf_industry_distribution(etf_code, etf_data):\n",
    "    \"\"\"åˆ†æETFçš„ç”¢æ¥­åˆ†å¸ƒ\"\"\"\n",
    "    if etf_code not in etf_data:\n",
    "        return None\n",
    "    \n",
    "    # é€™è£¡å¯ä»¥çµåˆyfinanceæ•¸æ“šä¾†å–å¾—ç”¢æ¥­è³‡è¨Š\n",
    "    constituents = etf_data[etf_code]['constituents']\n",
    "    \n",
    "    # æ¨¡æ“¬ç”¢æ¥­åˆ†å¸ƒæ•¸æ“š\n",
    "    industry_data = {\n",
    "        '2330': 'Technology',\n",
    "        '2454': 'Technology', \n",
    "        '2317': 'Technology',\n",
    "        '2308': 'Industrial',\n",
    "        '2881': 'Financial'\n",
    "    }\n",
    "    \n",
    "    industry_weights = {}\n",
    "    for constituent in constituents:\n",
    "        industry = industry_data.get(constituent['stock_code'], 'Other')\n",
    "        if industry not in industry_weights:\n",
    "            industry_weights[industry] = 0\n",
    "        industry_weights[industry] += constituent['weight']\n",
    "    \n",
    "    return industry_weights\n",
    "\n",
    "# åˆ†æç‰¹å®šETFçš„ç”¢æ¥­åˆ†å¸ƒ\n",
    "if '0050' in analyzer.etf_constituents:\n",
    "    industry_dist = analyze_etf_industry_distribution('0050', analyzer.etf_constituents)\n",
    "    print(\"ETF 0050 ç”¢æ¥­åˆ†å¸ƒ:\")\n",
    "    for industry, weight in sorted(industry_dist.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {industry}: {weight:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªå‹•åŒ–æ›´æ–°åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_automatic_update():\n",
    "    \"\"\"è¨­å®šè‡ªå‹•æ›´æ–°åŠŸèƒ½\"\"\"\n",
    "    print(\"è¨­å®šè‡ªå‹•æ›´æ–°åŠŸèƒ½...\")\n",
    "    \n",
    "    # é€™è£¡å¯ä»¥è¨­å®šå®šæœŸæ›´æ–°çš„ç¨‹å¼ç¢¼\n",
    "    # ä¾‹å¦‚ï¼šæ¯é€±æ›´æ–°ä¸€æ¬¡ETFæˆä»½è‚¡è³‡æ–™\n",
    "    \n",
    "    update_script = \"\"\"\n",
    "#!/usr/bin/env python3\n",
    "# ETFè‡ªå‹•æ›´æ–°è…³æœ¬\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/carbarcha_huang/Documents/tw-stock/stock_experiment')\n",
    "\n",
    "from taiwan_etf_analysis import TaiwanETFAnalyzer\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    print(f\"é–‹å§‹æ›´æ–°ETFè³‡æ–™ - {datetime.now()}\")\n",
    "    \n",
    "    analyzer = TaiwanETFAnalyzer()\n",
    "    \n",
    "    # æ›´æ–°ETFæ¸…å–®\n",
    "    analyzer.get_etf_list()\n",
    "    \n",
    "    # æ›´æ–°æˆä»½è‚¡è³‡æ–™\n",
    "    analyzer.collect_all_etf_data(max_etfs=20)\n",
    "    \n",
    "    # å„²å­˜è³‡æ–™\n",
    "    analyzer.save_data_to_csv()\n",
    "    \n",
    "    print(f\"ETFè³‡æ–™æ›´æ–°å®Œæˆ - {datetime.now()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "    \n",
    "    # å„²å­˜è‡ªå‹•æ›´æ–°è…³æœ¬\n",
    "    with open('../data/etf_auto_update.py', 'w', encoding='utf-8') as f:\n",
    "        f.write(update_script)\n",
    "    \n",
    "    print(\"è‡ªå‹•æ›´æ–°è…³æœ¬å·²å„²å­˜è‡³ ../data/etf_auto_update.py\")\n",
    "    print(\"å¯ä»¥ä½¿ç”¨ cron job è¨­å®šå®šæœŸåŸ·è¡Œï¼š\")\n",
    "    print(\"# æ¯é€±æ—¥å‡Œæ™¨2é»æ›´æ–°ETFè³‡æ–™\")\n",
    "    print(\"0 2 * * 0 /usr/bin/python3 /path/to/etf_auto_update.py\")\n",
    "\n",
    "setup_automatic_update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## çµè«–èˆ‡å¾ŒçºŒè¦åŠƒ\n",
    "\n",
    "æœ¬å¥—ETFåˆ†æç³»çµ±æä¾›äº†ä»¥ä¸‹åŠŸèƒ½ï¼š\n",
    "\n",
    "### âœ… å·²å®ŒæˆåŠŸèƒ½\n",
    "1. **ETFæ¸…å–®è‡ªå‹•æ”¶é›†**: å¾å¤šå€‹ä¾†æºå–å¾—å°è‚¡ETFæ¸…å–®\n",
    "2. **æˆä»½è‚¡è³‡æ–™çˆ¬å–**: è‡ªå‹•å–å¾—æ¯æª”ETFçš„æˆä»½è‚¡å’Œæ¬Šé‡\n",
    "3. **è³‡æ–™å„²å­˜èˆ‡è®€å–**: CSVæ ¼å¼å„²å­˜ï¼Œæ–¹ä¾¿å¾ŒçºŒä½¿ç”¨\n",
    "4. **é‡ç–Šåº¦åˆ†æ**: åˆ†æä¸åŒETFé–“çš„æˆä»½è‚¡é‡ç–Šæƒ…æ³\n",
    "5. **è¦–è¦ºåŒ–å±•ç¤º**: æ¬Šé‡åˆ†å¸ƒåœ–è¡¨å’Œåˆ†æå ±å‘Š\n",
    "6. **å€‹è‚¡æ›éšªåˆ†æ**: äº†è§£å€‹è‚¡åœ¨å„ETFä¸­çš„æ¬Šé‡åˆ†å¸ƒ\n",
    "\n",
    "### ğŸ”„ æŒçºŒæ”¹é€²\n",
    "1. **è³‡æ–™ä¾†æºå„ªåŒ–**: æ•´åˆæ›´å¤šå¯é çš„è³‡æ–™ä¾†æº\n",
    "2. **å³æ™‚æ›´æ–°**: å¯¦ç¾å³æ™‚æˆ–æº–å³æ™‚çš„è³‡æ–™æ›´æ–°\n",
    "3. **ç”¢æ¥­åˆ†æ**: çµåˆç”¢æ¥­åˆ†é¡é€²è¡Œæ›´æ·±å…¥åˆ†æ\n",
    "4. **é¢¨éšªåˆ†æ**: åŠ å…¥é¢¨éšªæŒ‡æ¨™å’Œç›¸é—œæ€§åˆ†æ\n",
    "5. **ç¸¾æ•ˆè¿½è¹¤**: çµåˆåƒ¹æ ¼è³‡æ–™é€²è¡Œç¸¾æ•ˆåˆ†æ\n",
    "\n",
    "### ğŸ“Š ä½¿ç”¨å»ºè­°\n",
    "1. å®šæœŸæ›´æ–°è³‡æ–™ä»¥ç¢ºä¿æº–ç¢ºæ€§\n",
    "2. çµåˆå…¶ä»–è²¡å‹™æŒ‡æ¨™é€²è¡Œç¶œåˆåˆ†æ\n",
    "3. æ³¨æ„ETFçš„äº¤æ˜“é‡å’Œæµå‹•æ€§\n",
    "4. è€ƒæ…®è²»ç”¨ç‡å’Œè¿½è¹¤èª¤å·®ç­‰å› ç´ \n",
    "\n",
    "é€™å¥—ç³»çµ±ç‚ºå°è‚¡ETFæŠ•è³‡æä¾›äº†å…¨é¢çš„æ•¸æ“šæ”¯æ´å’Œåˆ†æå·¥å…·ï¼Œæœ‰åŠ©æ–¼æŠ•è³‡æ±ºç­–çš„åˆ¶å®šã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}