#!/usr/bin/env python3
"""
å°è‚¡ETFæˆä»½è‚¡èˆ‡æ¬Šé‡çˆ¬èŸ²ç¨‹å¼
Taiwan Stock ETF Constituents and Weights Scraper

ä½œè€…: Claude AI
æ—¥æœŸ: 2025-01-11
ç”¨é€”: è‡ªå‹•æ”¶é›†å°ç£è‚¡å¸‚ETFçš„æˆä»½è‚¡å’Œæ¬Šé‡è³‡æ–™
"""

import pandas as pd
import numpy as np
import requests
import json
import time
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import os
import sys

class TaiwanETFScraper:
    """å°è‚¡ETFæ•¸æ“šçˆ¬èŸ²é¡åˆ¥"""
    
    def __init__(self, data_dir="../data/etf_data/"):
        """
        åˆå§‹åŒ–ETFçˆ¬èŸ²
        
        Args:
            data_dir (str): è³‡æ–™å„²å­˜ç›®éŒ„
        """
        self.data_dir = data_dir
        self.etf_list = []
        self.etf_constituents = {}
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # ç¢ºä¿è³‡æ–™ç›®éŒ„å­˜åœ¨
        os.makedirs(data_dir, exist_ok=True)
    
    def get_taiwan_etf_list(self):
        """
        å–å¾—å°ç£ETFæ¸…å–®
        
        Returns:
            list: ETFæ¸…å–®ï¼ŒåŒ…å«ä»£ç¢¼ã€åç¨±ç­‰è³‡è¨Š
        """
        print("æ­£åœ¨æ”¶é›†å°è‚¡ETFæ¸…å–®...")
        
        # å¸¸è¦‹å°è‚¡ETFæ¸…å–®
        common_etfs = [
            {'code': '0050', 'name': 'å…ƒå¤§å°ç£50', 'full_code': '0050.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '0056', 'name': 'å…ƒå¤§é«˜è‚¡æ¯', 'full_code': '0056.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00878', 'name': 'åœ‹æ³°æ°¸çºŒé«˜è‚¡æ¯', 'full_code': '00878.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00881', 'name': 'åœ‹æ³°å°ç£5G+', 'full_code': '00881.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00692', 'name': 'å¯Œé‚¦å…¬å¸æ²»ç†', 'full_code': '00692.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00757', 'name': 'çµ±ä¸€FANG+', 'full_code': '00757.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00762', 'name': 'å…ƒå¤§å…¨çƒäººå·¥æ™ºæ…§', 'full_code': '00762.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00894', 'name': 'ä¸­ä¿¡å°è³‡é«˜è‚¡æ¯', 'full_code': '00894.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00919', 'name': 'ç¾¤ç›Šå°ç£ç²¾é¸é«˜æ¯', 'full_code': '00919.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00929', 'name': 'å¾©è¯å°ç£ç§‘æŠ€å„ªæ¯', 'full_code': '00929.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '006208', 'name': 'å¯Œé‚¦å°50', 'full_code': '006208.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00631L', 'name': 'å…ƒå¤§å°ç£50æ­£2', 'full_code': '00631L.TW', 'type': 'æ§“æ¡¿å‹ETF'},
            {'code': '00632R', 'name': 'å…ƒå¤§å°ç£50å1', 'full_code': '00632R.TW', 'type': 'åå‘å‹ETF'},
            {'code': '00645', 'name': 'å¯Œé‚¦æ—¥æœ¬', 'full_code': '00645.TW', 'type': 'æµ·å¤–å‹ETF'},
            {'code': '00646', 'name': 'å…ƒå¤§S&P500', 'full_code': '00646.TW', 'type': 'æµ·å¤–å‹ETF'},
            {'code': '00660', 'name': 'å…ƒå¤§æ­æ´²50', 'full_code': '00660.TW', 'type': 'æµ·å¤–å‹ETF'},
            {'code': '00670L', 'name': 'å¯Œé‚¦NASDAQæ­£2', 'full_code': '00670L.TW', 'type': 'æ§“æ¡¿å‹ETF'},
            {'code': '00690', 'name': 'å…†è±è—ç±Œ30', 'full_code': '00690.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00701', 'name': 'åœ‹æ³°ä½æ³¢å‹•', 'full_code': '00701.TW', 'type': 'è‚¡ç¥¨å‹ETF'},
            {'code': '00713', 'name': 'å…ƒå¤§å°ç£é«˜æ¯ä½æ³¢', 'full_code': '00713.TW', 'type': 'è‚¡ç¥¨å‹ETF'}
        ]
        
        try:
            # å˜—è©¦å¾TWSE APIå–å¾—æ›´å®Œæ•´çš„ETFæ¸…å–®
            url = "https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX?response=json&type=ETF"
            response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                
                # è§£æETFè³‡æ–™
                if 'data9' in data:
                    api_etfs = []
                    for item in data['data9']:
                        if len(item) >= 2:
                            etf_code = item[0]
                            etf_name = item[1]
                            
                            # éæ¿¾æœ‰æ•ˆçš„ETFä»£ç¢¼
                            if etf_code and len(etf_code) >= 4:
                                api_etfs.append({
                                    'code': etf_code,
                                    'name': etf_name,
                                    'full_code': f"{etf_code}.TW",
                                    'type': 'ETF'
                                })
                    
                    # åˆä½µAPIå’Œå¸¸è¦‹ETFæ¸…å–®
                    existing_codes = {etf['code'] for etf in api_etfs}
                    for etf in common_etfs:
                        if etf['code'] not in existing_codes:
                            api_etfs.append(etf)
                    
                    self.etf_list = api_etfs
                else:
                    self.etf_list = common_etfs
            else:
                self.etf_list = common_etfs
                
        except Exception as e:
            print(f"å¾APIå–å¾—ETFæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œä½¿ç”¨é è¨­æ¸…å–®: {str(e)}")
            self.etf_list = common_etfs
        
        print(f"æˆåŠŸæ”¶é›†åˆ° {len(self.etf_list)} æª”ETF")
        return self.etf_list
    
    def get_etf_constituents_mock(self, etf_code):
        """
        å–å¾—ETFæˆä»½è‚¡è³‡æ–™ (æ¨¡æ“¬ç‰ˆæœ¬)
        å¯¦éš›ä½¿ç”¨æ™‚éœ€è¦æ›¿æ›ç‚ºçœŸå¯¦çš„APIæˆ–çˆ¬èŸ²é‚è¼¯
        
        Args:
            etf_code (str): ETFä»£ç¢¼
            
        Returns:
            list: æˆä»½è‚¡æ¸…å–®
        """
        # æ¨¡æ“¬æˆä»½è‚¡è³‡æ–™
        mock_data = {
            '0050': [
                {'stock_code': '2330', 'stock_name': 'å°ç©é›»', 'weight': 47.52, 'shares': 1000000},
                {'stock_code': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'weight': 8.23, 'shares': 150000},
                {'stock_code': '2317', 'stock_name': 'é´»æµ·', 'weight': 4.15, 'shares': 500000},
                {'stock_code': '2308', 'stock_name': 'å°é”é›»', 'weight': 2.87, 'shares': 80000},
                {'stock_code': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'weight': 2.53, 'shares': 200000},
                {'stock_code': '2382', 'stock_name': 'å»£é”', 'weight': 2.31, 'shares': 180000},
                {'stock_code': '2412', 'stock_name': 'ä¸­è¯é›»', 'weight': 2.08, 'shares': 160000},
                {'stock_code': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'weight': 1.95, 'shares': 140000},
                {'stock_code': '2886', 'stock_name': 'å…†è±é‡‘', 'weight': 1.72, 'shares': 120000},
                {'stock_code': '2303', 'stock_name': 'è¯é›»', 'weight': 1.61, 'shares': 300000}
            ],
            '0056': [
                {'stock_code': '2330', 'stock_name': 'å°ç©é›»', 'weight': 15.23, 'shares': 300000},
                {'stock_code': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'weight': 8.91, 'shares': 120000},
                {'stock_code': '2317', 'stock_name': 'é´»æµ·', 'weight': 6.72, 'shares': 400000},
                {'stock_code': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'weight': 4.33, 'shares': 200000},
                {'stock_code': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'weight': 3.84, 'shares': 180000},
                {'stock_code': '2412', 'stock_name': 'ä¸­è¯é›»', 'weight': 3.56, 'shares': 150000},
                {'stock_code': '2886', 'stock_name': 'å…†è±é‡‘', 'weight': 3.21, 'shares': 130000},
                {'stock_code': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'weight': 2.97, 'shares': 110000},
                {'stock_code': '2308', 'stock_name': 'å°é”é›»', 'weight': 2.68, 'shares': 70000},
                {'stock_code': '2892', 'stock_name': 'ç¬¬ä¸€é‡‘', 'weight': 2.45, 'shares': 100000}
            ],
            '00878': [
                {'stock_code': '2330', 'stock_name': 'å°ç©é›»', 'weight': 12.45, 'shares': 250000},
                {'stock_code': '2454', 'stock_name': 'è¯ç™¼ç§‘', 'weight': 7.86, 'shares': 100000},
                {'stock_code': '2317', 'stock_name': 'é´»æµ·', 'weight': 6.23, 'shares': 350000},
                {'stock_code': '2891', 'stock_name': 'ä¸­ä¿¡é‡‘', 'weight': 5.12, 'shares': 190000},
                {'stock_code': '2881', 'stock_name': 'å¯Œé‚¦é‡‘', 'weight': 4.78, 'shares': 170000},
                {'stock_code': '2412', 'stock_name': 'ä¸­è¯é›»', 'weight': 4.33, 'shares': 140000},
                {'stock_code': '2886', 'stock_name': 'å…†è±é‡‘', 'weight': 3.95, 'shares': 120000},
                {'stock_code': '2882', 'stock_name': 'åœ‹æ³°é‡‘', 'weight': 3.67, 'shares': 105000},
                {'stock_code': '2308', 'stock_name': 'å°é”é›»', 'weight': 3.24, 'shares': 65000},
                {'stock_code': '2892', 'stock_name': 'ç¬¬ä¸€é‡‘', 'weight': 2.89, 'shares': 95000}
            ]
        }
        
        # ç‚ºå…¶ä»–ETFç”Ÿæˆéš¨æ©Ÿä½†åˆç†çš„æˆä»½è‚¡è³‡æ–™
        if etf_code not in mock_data:
            # ä½¿ç”¨å°ç£å‰50å¤§è‚¡ç¥¨çš„å­é›†
            common_stocks = [
                {'code': '2330', 'name': 'å°ç©é›»'},
                {'code': '2454', 'name': 'è¯ç™¼ç§‘'},
                {'code': '2317', 'name': 'é´»æµ·'},
                {'code': '2308', 'name': 'å°é”é›»'},
                {'code': '2881', 'name': 'å¯Œé‚¦é‡‘'},
                {'code': '2382', 'name': 'å»£é”'},
                {'code': '2412', 'name': 'ä¸­è¯é›»'},
                {'code': '2891', 'name': 'ä¸­ä¿¡é‡‘'},
                {'code': '2886', 'name': 'å…†è±é‡‘'},
                {'code': '2303', 'name': 'è¯é›»'},
                {'code': '2882', 'name': 'åœ‹æ³°é‡‘'},
                {'code': '2892', 'name': 'ç¬¬ä¸€é‡‘'},
                {'code': '2884', 'name': 'ç‰å±±é‡‘'},
                {'code': '2395', 'name': 'ç ”è¯'},
                {'code': '2409', 'name': 'å‹é”'}
            ]
            
            # éš¨æ©Ÿé¸å–10-15æª”è‚¡ç¥¨
            import random
            random.seed(hash(etf_code) % 1000)  # ç¢ºä¿æ¯æ¬¡é‹è¡Œçµæœä¸€è‡´
            
            num_stocks = random.randint(10, 15)
            selected_stocks = random.sample(common_stocks, min(num_stocks, len(common_stocks)))
            
            # ç”Ÿæˆæ¬Šé‡åˆ†é…
            weights = []
            for i in range(len(selected_stocks)):
                if i == 0:  # ç¬¬ä¸€å¤§æŒè‚¡
                    weight = random.uniform(15, 25)
                elif i < 3:  # å‰ä¸‰å¤§
                    weight = random.uniform(5, 12)
                elif i < 5:  # å‰äº”å¤§
                    weight = random.uniform(3, 8)
                else:  # å…¶ä»–
                    weight = random.uniform(1, 5)
                weights.append(weight)
            
            # æ­£è¦åŒ–æ¬Šé‡
            total_weight = sum(weights)
            normalized_weights = [w / total_weight * 80 for w in weights]  # å‡è¨­å‰80%
            
            constituents = []
            for i, stock in enumerate(selected_stocks):
                constituents.append({
                    'stock_code': stock['code'],
                    'stock_name': stock['name'],
                    'weight': round(normalized_weights[i], 2),
                    'shares': random.randint(50000, 500000)
                })
            
            mock_data[etf_code] = constituents
        
        return mock_data.get(etf_code, [])
    
    def collect_all_etf_data(self, max_etfs=None, delay=1.0):
        """
        æ”¶é›†æ‰€æœ‰ETFçš„æˆä»½è‚¡è³‡æ–™
        
        Args:
            max_etfs (int): æœ€å¤§æ”¶é›†æ•¸é‡ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
            delay (float): è«‹æ±‚é–“éš”æ™‚é–“(ç§’)
            
        Returns:
            dict: ETFæˆä»½è‚¡è³‡æ–™å­—å…¸
        """
        if not self.etf_list:
            self.get_taiwan_etf_list()
        
        etfs_to_process = self.etf_list[:max_etfs] if max_etfs else self.etf_list
        
        print(f"é–‹å§‹æ”¶é›† {len(etfs_to_process)} æª”ETFçš„æˆä»½è‚¡è³‡æ–™...")
        
        success_count = 0
        for i, etf in enumerate(etfs_to_process):
            print(f"æ­£åœ¨è™•ç† {i+1}/{len(etfs_to_process)}: {etf['code']} - {etf['name']}")
            
            try:
                constituents = self.get_etf_constituents_mock(etf['code'])
                
                if constituents:
                    self.etf_constituents[etf['code']] = {
                        'name': etf['name'],
                        'full_code': etf['full_code'],
                        'type': etf.get('type', 'ETF'),
                        'constituents': constituents,
                        'total_constituents': len(constituents),
                        'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }
                    success_count += 1
                    print(f"  âœ“ æˆåŠŸæ”¶é›† {len(constituents)} æª”æˆä»½è‚¡")
                else:
                    print(f"  âœ— ç„¡æ³•å–å¾—æˆä»½è‚¡è³‡æ–™")
                
                # é¿å…éåº¦è«‹æ±‚
                if delay > 0:
                    time.sleep(delay)
                    
            except Exception as e:
                print(f"  âœ— è™•ç† {etf['code']} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                continue
        
        print(f"\nè³‡æ–™æ”¶é›†å®Œæˆï¼æˆåŠŸæ”¶é›† {success_count}/{len(etfs_to_process)} æª”ETFçš„æˆä»½è‚¡è³‡æ–™")
        return self.etf_constituents
    
    def save_to_csv(self):
        """
        å„²å­˜ETFè³‡æ–™åˆ°CSVæª”æ¡ˆ
        
        Returns:
            tuple: (ETFæ¸…å–®DataFrame, æ‰€æœ‰æˆä»½è‚¡DataFrame)
        """
        print("æ­£åœ¨å„²å­˜è³‡æ–™åˆ°CSVæª”æ¡ˆ...")
        
        # å„²å­˜ETFæ¸…å–®
        etf_df = pd.DataFrame(self.etf_list)
        etf_csv_path = os.path.join(self.data_dir, "taiwan_etf_list.csv")
        etf_df.to_csv(etf_csv_path, index=False, encoding='utf-8-sig')
        print(f"ETFæ¸…å–®å·²å„²å­˜è‡³: {etf_csv_path}")
        
        # å„²å­˜å€‹åˆ¥ETFæˆä»½è‚¡è³‡æ–™
        for etf_code, data in self.etf_constituents.items():
            constituents_df = pd.DataFrame(data['constituents'])
            constituents_df['etf_code'] = etf_code
            constituents_df['etf_name'] = data['name']
            constituents_df['etf_type'] = data['type']
            constituents_df['last_update'] = data['last_update']
            
            csv_path = os.path.join(self.data_dir, f"{etf_code}_constituents.csv")
            constituents_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        # å„²å­˜åˆä½µçš„æ‰€æœ‰æˆä»½è‚¡è³‡æ–™
        all_constituents = []
        for etf_code, data in self.etf_constituents.items():
            for constituent in data['constituents']:
                all_constituents.append({
                    'etf_code': etf_code,
                    'etf_name': data['name'],
                    'etf_type': data['type'],
                    'stock_code': constituent['stock_code'],
                    'stock_name': constituent['stock_name'],
                    'weight': constituent['weight'],
                    'shares': constituent.get('shares', 0),
                    'last_update': data['last_update']
                })
        
        all_df = pd.DataFrame(all_constituents)
        all_csv_path = os.path.join(self.data_dir, "all_etf_constituents.csv")
        all_df.to_csv(all_csv_path, index=False, encoding='utf-8-sig')
        print(f"åˆä½µæˆä»½è‚¡è³‡æ–™å·²å„²å­˜è‡³: {all_csv_path}")
        
        print(f"æ‰€æœ‰è³‡æ–™å·²å„²å­˜è‡³ç›®éŒ„: {self.data_dir}")
        return etf_df, all_df
    
    def load_from_csv(self):
        """
        å¾CSVæª”æ¡ˆè¼‰å…¥ETFè³‡æ–™
        
        Returns:
            bool: è¼‰å…¥æ˜¯å¦æˆåŠŸ
        """
        try:
            # è¼‰å…¥ETFæ¸…å–®
            etf_csv_path = os.path.join(self.data_dir, "taiwan_etf_list.csv")
            if os.path.exists(etf_csv_path):
                etf_df = pd.read_csv(etf_csv_path)
                self.etf_list = etf_df.to_dict('records')
                print(f"å·²è¼‰å…¥ {len(self.etf_list)} æª”ETFæ¸…å–®")
            
            # è¼‰å…¥æˆä»½è‚¡è³‡æ–™
            all_csv_path = os.path.join(self.data_dir, "all_etf_constituents.csv")
            if os.path.exists(all_csv_path):
                all_df = pd.read_csv(all_csv_path)
                
                # é‡å»ºetf_constituentsçµæ§‹
                self.etf_constituents = {}
                for etf_code in all_df['etf_code'].unique():
                    etf_data = all_df[all_df['etf_code'] == etf_code]
                    constituents = []
                    
                    for _, row in etf_data.iterrows():
                        constituents.append({
                            'stock_code': row['stock_code'],
                            'stock_name': row['stock_name'],
                            'weight': row['weight'],
                            'shares': row.get('shares', 0)
                        })
                    
                    self.etf_constituents[etf_code] = {
                        'name': etf_data.iloc[0]['etf_name'],
                        'type': etf_data.iloc[0]['etf_type'],
                        'constituents': constituents,
                        'total_constituents': len(constituents),
                        'last_update': etf_data.iloc[0]['last_update']
                    }
                
                print(f"å·²è¼‰å…¥ {len(self.etf_constituents)} æª”ETFæˆä»½è‚¡è³‡æ–™")
                return True
            
        except Exception as e:
            print(f"è¼‰å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
        
        return False
    
    def get_summary_statistics(self):
        """
        å–å¾—è³‡æ–™æ‘˜è¦çµ±è¨ˆ
        
        Returns:
            dict: çµ±è¨ˆè³‡è¨Š
        """
        if not self.etf_constituents:
            return {}
        
        # å»ºç«‹åˆ†æç”¨DataFrame
        all_data = []
        for etf_code, data in self.etf_constituents.items():
            for constituent in data['constituents']:
                all_data.append({
                    'etf_code': etf_code,
                    'etf_name': data['name'],
                    'etf_type': data['type'],
                    'stock_code': constituent['stock_code'],
                    'stock_name': constituent['stock_name'],
                    'weight': constituent['weight']
                })
        
        df = pd.DataFrame(all_data)
        
        # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
        stats = {
            'total_etfs': len(self.etf_constituents),
            'total_records': len(df),
            'unique_stocks': df['stock_code'].nunique(),
            'avg_constituents_per_etf': df.groupby('etf_code').size().mean(),
            'top_stocks_by_frequency': df['stock_code'].value_counts().head(10).to_dict(),
            'top_stocks_by_total_weight': df.groupby('stock_code')['weight'].sum().sort_values(ascending=False).head(10).to_dict(),
            'etf_types': df['etf_type'].value_counts().to_dict(),
            'weight_distribution': {
                'mean': df['weight'].mean(),
                'median': df['weight'].median(),
                'std': df['weight'].std(),
                'min': df['weight'].min(),
                'max': df['weight'].max()
            }
        }
        
        return stats
    
    def print_summary_report(self):
        """åˆ—å°æ‘˜è¦å ±å‘Š"""
        stats = self.get_summary_statistics()
        
        if not stats:
            print("ç„¡è³‡æ–™å¯ä¾›åˆ†æ")
            return
        
        print("=" * 60)
        print("å°è‚¡ETFæˆä»½è‚¡åˆ†ææ‘˜è¦å ±å‘Š")
        print("=" * 60)
        
        print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"  - åˆ†æETFæ•¸é‡: {stats['total_etfs']}")
        print(f"  - ç¸½æˆä»½è‚¡è¨˜éŒ„: {stats['total_records']}")
        print(f"  - ç¨ç‰¹è‚¡ç¥¨æ•¸é‡: {stats['unique_stocks']}")
        print(f"  - å¹³å‡æ¯æª”ETFæˆä»½è‚¡æ•¸: {stats['avg_constituents_per_etf']:.1f}")
        
        print(f"\nğŸ† æœ€å¸¸å‡ºç¾çš„è‚¡ç¥¨ (å‰10å):")
        for i, (stock_code, count) in enumerate(stats['top_stocks_by_frequency'].items(), 1):
            print(f"  {i:2d}. {stock_code}: å‡ºç¾åœ¨ {count} æª”ETFä¸­")
        
        print(f"\nğŸ’° ç¸½æ¬Šé‡æœ€é«˜çš„è‚¡ç¥¨ (å‰10å):")
        for i, (stock_code, total_weight) in enumerate(stats['top_stocks_by_total_weight'].items(), 1):
            print(f"  {i:2d}. {stock_code}: ç¸½æ¬Šé‡ {total_weight:.2f}%")
        
        print(f"\nğŸ“ˆ ETFé¡å‹åˆ†å¸ƒ:")
        for etf_type, count in stats['etf_types'].items():
            print(f"  - {etf_type}: {count} æª”")
        
        print(f"\nğŸ“Š æ¬Šé‡åˆ†å¸ƒçµ±è¨ˆ:")
        weight_stats = stats['weight_distribution']
        print(f"  - å¹³å‡æ¬Šé‡: {weight_stats['mean']:.2f}%")
        print(f"  - ä¸­ä½æ•¸æ¬Šé‡: {weight_stats['median']:.2f}%")
        print(f"  - æ¬Šé‡æ¨™æº–å·®: {weight_stats['std']:.2f}%")
        print(f"  - æœ€å°æ¬Šé‡: {weight_stats['min']:.2f}%")
        print(f"  - æœ€å¤§æ¬Šé‡: {weight_stats['max']:.2f}%")
        
        print("\n" + "=" * 60)


def main():
    """ä¸»ç¨‹å¼"""
    print("å°è‚¡ETFæˆä»½è‚¡èˆ‡æ¬Šé‡çˆ¬èŸ²ç¨‹å¼")
    print("=" * 40)
    
    # åˆå§‹åŒ–çˆ¬èŸ²
    scraper = TaiwanETFScraper()
    
    # å–å¾—ETFæ¸…å–®
    etf_list = scraper.get_taiwan_etf_list()
    
    # æ”¶é›†æˆä»½è‚¡è³‡æ–™ (å…ˆè™•ç†å‰10æª”åšæ¸¬è©¦)
    etf_data = scraper.collect_all_etf_data(max_etfs=10)
    
    # å„²å­˜è³‡æ–™
    etf_df, all_df = scraper.save_to_csv()
    
    # åˆ—å°æ‘˜è¦å ±å‘Š
    scraper.print_summary_report()
    
    print(f"\nâœ… ç¨‹å¼åŸ·è¡Œå®Œæˆï¼")
    print(f"è³‡æ–™å·²å„²å­˜è‡³: {scraper.data_dir}")


if __name__ == "__main__":
    main()